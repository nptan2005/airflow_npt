# Gi·ªõi thi·ªáu:

## M·ª•c ƒë√≠ch d·ª± √°n:
D·ª± √°n n√†y x·ª≠ l√Ω vi·ªác l√™n l·ªãch, th·ª±c thi v√† l∆∞u tr·ªØ d·ªØ li·ªáu sau khi x·ª≠ l√Ω. N√≥ t√≠ch h·ª£p v·ªõi c∆° s·ªü d·ªØ li·ªáu Oracle, c√°c server SFTP v√† d·ªãch v·ª• email.

Project s·ª≠ d·ª•ng S·ª≠ d·ª•ng airflow, ƒë∆∞·ª£c m·ªü r·ªông b·∫±ng c√°c th∆∞ vi√™n python (schedule service) do t√¥i vi·∫øt v√† √°p d·ª•ng v√†i t·ªï ch·ª©c ƒë√£ l√†m tr∆∞·ªõc ƒë√¢y.

## t√°c gi·∫£:
**email:** *nptan2005@gmail.com*

# üìä T·ªïng Quan Apache Airflow

---

## 1Ô∏è‚É£ T·ªïng quan

**Apache Airflow** l√† m·ªôt n·ªÅn t·∫£ng m√£ ngu·ªìn m·ªü d√πng ƒë·ªÉ l·∫≠p l·ªãch v√† gi√°m s√°t lu·ªìng c√¥ng vi·ªác (workflow) theo c√°ch l·∫≠p tr√¨nh ƒë∆∞·ª£c.  
Airflow cho ph√©p b·∫°n ƒë·ªãnh nghƒ©a c√°c DAGs (Directed Acyclic Graphs) ‚Äî m·ªôt chu·ªói c√°c task c√≥ quan h·ªá ph·ª• thu·ªôc logic ‚Äî b·∫±ng Python.

> üß† "Vi·∫øt DAG nh∆∞ vi·∫øt code, kh√¥ng c·∫ßn c·∫•u h√¨nh ph·ª©c t·∫°p."

---

## 2Ô∏è‚É£ T√≠nh nƒÉng n·ªïi b·∫≠t


| T√≠nh nƒÉng             | M√¥ t·∫£                                             |
|-----------------------|--------------------------------------------------|
| üß© Modular            | C√≥ th·ªÉ m·ªü r·ªông b·∫±ng plugin, vi·∫øt operator t√πy ch·ªânh |
| üõ† L·∫≠p l·ªãch linh ho·∫°t | D·ª±a tr√™n cron ho·∫∑c th·ªùi gian t√πy ch·ªânh           |
| üìä Web UI m·∫°nh m·∫Ω     | Theo d√µi DAG, log, retry task...                 |
| üí• Retry, Alert, SLA  | T·ª± ƒë·ªông retry, g·ª≠i email khi task fail          |
| üßµ Parallel execution | Ch·∫°y task song song qua Celery, Kubernetes      |
| üîê RBAC UI            | Ph√¢n quy·ªÅn ng∆∞·ªùi d√πng r√µ r√†ng                   |


---

## 3Ô∏è‚É£ ·ª®ng d·ª•ng th·ª±c t·∫ø


| Lƒ©nh v·ª±c         | ·ª®ng d·ª•ng                                    |
|------------------|---------------------------------------------|
| üéØ D·ªØ li·ªáu l·ªõn   | ETL, chu·∫©n h√≥a d·ªØ li·ªáu, Spark/Hadoop        |
| üß™ Khoa h·ªçc d·ªØ li·ªáu | Training ML model ƒë·ªãnh k·ª≥                |
| üõí E-commerce     | T·ª± ƒë·ªông h√≥a b√°o c√°o b√°n h√†ng               |
| üì¨ Marketing      | G·ª≠i email h√†ng lo·∫°t theo l·ªãch              |
| üßæ K·∫ø to√°n        | ƒê·ªëi so√°t d·ªØ li·ªáu, ch·∫°y batch jobs          |


---

## 4Ô∏è‚É£ Kh·∫£ nƒÉng m·ªü r·ªông

|---------------------|------------------------------------------------------|
| Mode                | ƒê·∫∑c ƒëi·ªÉm                                             |
|---------------------|------------------------------------------------------|
| SequentialExecutor  | Ch·∫°y tu·∫ßn t·ª± ‚Äì ch·ªâ d√πng khi test                     |
|---------------------|------------------------------------------------------|
| LocalExecutor       | Ch·∫°y song song trong 1 m√°y                           |
|---------------------|------------------------------------------------------|
| CeleryExecutor      | Scale b·∫±ng nhi·ªÅu worker, s·ª≠ d·ª•ng Redis/RabbitMQ      |
|---------------------|------------------------------------------------------|
| KubernetesExecutor  | T·ª± ƒë·ªông spawn pod cho t·ª´ng task ‚Äì l√Ω t∆∞·ªüng cho cloud |
|---------------------|------------------------------------------------------|


---

## 5Ô∏è‚É£ Ki·∫øn tr√∫c & c√°c th√†nh ph·∫ßn ch√≠nh

```plaintext
                         +-----------------------+
                         |   Web Server (UI)     |
                         |   Flask + Gunicorn    |
                         +-----------+-----------+
                                     |
                                     v
                              Scheduler (Trigger DAG)
                                     |
                                     v
              +----------------------+----------------------+
              |                      |                      |
              v                      v                      v
         Worker 1               Worker 2               Worker N
          (task)                 (task)                 (task)
              |                      |                      |
              +----------------------+----------------------+
                                     |
                           Redis/RabbitMQ (Broker)
                                     |
                          PostgreSQL/MySQL (Metadata DB)
```

### üì¶ M√¥ t·∫£ chi ti·∫øt:


|--------------|--------------------------------------|-------------------------------------------|
| Th√†nh ph·∫ßn   | M√¥ t·∫£                                | T√≠nh nƒÉng ch√≠nh                           |
|--------------|--------------------------------------|-------------------------------------------|
| Webserver    | Giao di·ªán ng∆∞·ªùi d√πng (Flask)         | Xem DAG, trigger, log                     | 
|--------------|--------------------------------------|-------------------------------------------|
| Scheduler    | L·∫≠p l·ªãch DAG theo th·ªùi gian          | Theo d√µi tr·∫°ng th√°i & l√™n l·ªãch task       |
|--------------|--------------------------------------|-------------------------------------------|
| Worker       | Th·ª±c thi task DAG                    | C√≥ th·ªÉ scale h√†ng ch·ª•c                    |
|--------------|--------------------------------------|-------------------------------------------|
| Broker       | Giao ti·∫øp gi·ªØa Scheduler v√† Worker   | Redis ho·∫∑c RabbitMQ                       |
|--------------|--------------------------------------|-------------------------------------------|
| Metadata DB  | L∆∞u tr·∫°ng th√°i, DAG, task...         | C·ª±c k·ª≥ quan tr·ªçng, kh√¥ng ƒë∆∞·ª£c m·∫•t d·ªØ li·ªáu |
|--------------|--------------------------------------|-------------------------------------------|
| Flower       | Monitor queue Celery                 | Xem queue, retry, tr·∫°ng th√°i worker       |
|--------------|--------------------------------------|-------------------------------------------|


---

‚úÖ V·ªõi ki·∫øn tr√∫c n√†y, Airflow r·∫•t ph√π h·ª£p ƒë·ªÉ scale t·ª´ m√°y local l√™n production cloud (GCP, AWS, Azure).

-----------------------------------------------------------------------------

# ‚öôÔ∏è README: M√¥ h√¨nh tri·ªÉn khai Apache Airflow theo Docker & Microservices + CI/CD

---

## üß≠ M·ª•c ti√™u

M√¥ h√¨nh ho√° h·ªá th·ªëng Airflow linh ho·∫°t, hi·ªán ƒë·∫°i theo ki·∫øn tr√∫c **microservices**, k·∫øt h·ª£p v·ªõi CI/CD ƒë·ªÉ:

- ‚úÖ T·ª± ƒë·ªông build, push, deploy images
- ‚úÖ T√°ch bi·ªát t·ª´ng th√†nh ph·∫ßn trong container
- ‚úÖ C√≥ th·ªÉ scale ri√™ng c√°c worker, proxy, etc.
- ‚úÖ T·ª± ƒë·ªông ki·ªÉm th·ª≠ DAG tr∆∞·ªõc khi ƒë∆∞a v√†o production

---

## üß± M√¥ h√¨nh t·ªïng quan h·ªá th·ªëng

```plaintext
                              [ GitHub / GitLab ]
                                       |
                                       v
                             +------------------+
                             |   CI/CD Pipeline |
                             | (GitHub Actions) |
                             +------------------+
                                       |
        -------------------------------------------------------
        |                      |                              |
        v                      v                              v
 [Docker Build]       [Unit test DAGs]             [Push image airflow-nptan:tag]
        |
        v
[docker-compose-prod.yaml / Kubernetes Helm chart]
        |
        v
    +------------------------+      +--------------------+
    |  airflow-webserver     | <--> |  nginx proxy (TLS) |
    +------------------------+      +--------------------+
        |
        v
+--------------------------+
|  airflow-scheduler       |
+--------------------------+
        |
        v
+--------------------------+
| Redis / RabbitMQ Broker  |
+--------------------------+
        |
        v
+--------------------------+
|  airflow-worker(s)       | <---- scale horizontally
+--------------------------+
        |
        v
+--------------------------+
| PostgreSQL (metadata DB) |
+--------------------------+
```

---

## üß© Th√†nh ph·∫ßn & vai tr√≤

| Th√†nh ph·∫ßn         | Vai tr√≤ |
|--------------------|--------|
| **GitHub CI/CD**   | Ki·ªÉm th·ª≠, build, push image |
| **Docker Compose / K8s** | Tri·ªÉn khai Airflow stack |
| **Nginx proxy**    | Reverse proxy, SSL |
| **Webserver**      | Giao di·ªán qu·∫£n tr·ªã |
| **Scheduler**      | L·∫≠p l·ªãch DAG |
| **Worker(s)**      | Th·ª±c thi task (scale) |
| **Redis**          | Queue broker |
| **PostgreSQL**     | L∆∞u tr·∫°ng th√°i DAG/task |

---

## üîÅ CI/CD m·∫´u v·ªõi GitHub Actions

```yaml
name: Deploy Airflow

on:
  push:
    branches: [ main ]

jobs:
  build-and-deploy:
    runs-on: ubuntu-latest

    steps:
    - uses: actions/checkout@v3
    - uses: docker/setup-buildx-action@v2

    - name: Build & Push image
      uses: docker/build-push-action@v4
      with:
        context: .
        tags: your_user/airflow-nptan:latest
        push: true

    - name: Trigger Deploy Server (SSH)
      uses: appleboy/ssh-action@v1
      with:
        host: ${{ secrets.HOST }}
        username: ${{ secrets.USER }}
        key: ${{ secrets.SSH_KEY }}
        script: |
          cd airflow-deploy
          docker compose pull
          docker compose up -d
```

---

## üîê Secrets CI/CD c·∫ßn thi·∫øt

| T√™n bi·∫øn | M√¥ t·∫£ |
|----------|------|
| `DOCKER_USER` | Docker Hub username |
| `DOCKER_PASS` | Docker Hub password/token |
| `SSH_KEY`     | Private key deploy server |
| `HOST`        | IP/FQDN c·ªßa m√°y ch·ªß |
| `USER`        | User SSH |

---

## üîÑ DAG Sync m√¥ h√¨nh production

### C√°ch ph·ªï bi·∫øn:
1. Mount volume t·ª´ NFS ch·ª©a DAG
2. ƒê·ªìng b·ªô DAG t·ª´ Git v·ªÅ container b·∫±ng `git pull` + cron
3. D√πng `airflow-dags-git-sync` ho·∫∑c sidecar container (K8s)

---

‚úÖ M√¥ h√¨nh n√†y ph√π h·ª£p v·ªõi production c·∫ßn:
- Ch·∫°y nhi·ªÅu DAG ph·ª©c t·∫°p
- Theo d√µi l·ªãch s·ª≠, log chi ti·∫øt
- C√≥ quy tr√¨nh CI/CD m·∫°nh m·∫Ω
- T·ªëi ∆∞u hi·ªáu nƒÉng v√† kh·∫£ nƒÉng m·ªü r·ªông



-----------------------------------------------------------------------------
# üìò Airflow Production & Development Setup Guide

## üì¶ 1. Docker Compose (Development Mode)

Docker Compose l√† c√°ch nhanh g·ªçn ƒë·ªÉ kh·ªüi ch·∫°y to√†n b·ªô Airflow stack tr√™n 1 m√°y dev (macOS, Windows, Linux).

### ‚úÖ C·∫•u tr√∫c ƒëi·ªÉn h√¨nh g·ªìm:
- `airflow-webserver`
- `airflow-scheduler`
- `airflow-worker` (scale ƒë∆∞·ª£c)
- `airflow-init`
- `flower` (monitor worker)
- `postgres` (metadata DB)
- `redis` (Celery broker)
- `nginx` (proxy/nginx optional)

### ‚úÖ Image chu·∫©n:

```yaml
x-airflow-common:
  &airflow-common
  image: airflow-nptan:1.0.0
  build:
    context: .
    dockerfile: ./airflow.Dockerfile
```

### ‚úÖ Clean container names:

```yaml
services:
  airflow-webserver:
    <<: *airflow-common
    container_name: airflow-webserver

  airflow-scheduler:
    <<: *airflow-common
    container_name: airflow-scheduler

  # ...v·ªõi c√°c service c√≤n l·∫°i

  postgres:
    image: postgres:13
    container_name: airflow-postgres
    volumes:
      - postgres-db-volume:/var/lib/postgresql/data
```

‚õî Kh√¥ng √°p d·ª•ng `<<: *airflow-common` cho `postgres`, `redis`, ho·∫∑c `nginx`.

---

## üß© 2. Docker Named Volume: `postgres-db-volume`

Volume n√†y ƒë∆∞·ª£c Docker qu·∫£n l√Ω v√† **kh√¥ng c·∫ßn t·∫°o th·ªß c√¥ng**.

### ‚úÖ Backup volume ra file `.tar.gz`:

```bash
docker run --rm   -v airflow_bvb_postgres-db-volume:/volume   -v $(pwd)/db_backup:/backup   alpine   tar czf /backup/postgres_data_backup.tar.gz -C /volume .
```

### ‚úÖ Restore l·∫°i:

```bash
docker volume create airflow_bvb_postgres-db-volume

docker run --rm   -v airflow_bvb_postgres-db-volume:/volume   -v $(pwd)/db_backup:/backup   alpine   tar xzf /backup/postgres_data_backup.tar.gz -C /volume
```

---

## üß† 3. T·∫°i sao `container_name` khi·∫øn b·∫°n kh√¥ng scale ƒë∆∞·ª£c?

```yaml
services:
  airflow-worker:
    container_name: airflow-worker
```

‚Üí Khi scale:

```bash
docker compose up --scale airflow-worker=2
```

‚Üí Docker l·ªói do **2 container tr√πng t√™n**.

### ‚úÖ Gi·∫£i ph√°p:
- ‚ùå ƒê·ª´ng d√πng `container_name` n·∫øu mu·ªën scale
- ‚úÖ D√πng `-p airflow` ƒë·ªÉ ƒë·ªïi prefix project

---

## üöÄ 4. Production Deployment (Recommended)

| Service         | N√™n t√°ch ra? | Ghi ch√∫ |
|----------------|--------------|--------|
| Webserver      | ‚úÖ           | Cho UI ri√™ng |
| Scheduler      | ‚úÖ           | ƒê·∫£m b·∫£o trigger |
| Worker(s)      | ‚úÖ‚úÖ‚úÖ       | N√™n scale |
| Redis          | ‚úÖ           | Broker |
| PostgreSQL     | ‚úÖ           | Metadata DB |
| Nginx / Proxy  | ‚úÖ           | TLS, route |
| Flower         | ‚úÖ           | Gi√°m s√°t task |
| DAG Storage    | ‚úÖ (optional)| S3/NFS ƒë·ªÉ ƒë·ªìng b·ªô DAG |

---

## ‚öôÔ∏è C√¥ng c·ª• production n√™n d√πng:

- ‚úÖ Docker Compose (dev/staging)
- ‚úÖ Kubernetes (Helm chart Airflow)
- ‚úÖ AWS ECS / GCP GKE / Azure AKS
- ‚úÖ Redis Cluster, PostgreSQL RDS
- ‚úÖ Gi√°m s√°t: Prometheus, Grafana, Sentry

---

## üß† So s√°nh Docker Compose vs C√†i Service Truy·ªÅn Th·ªëng

| Ti√™u ch√≠          | Docker Compose         | C√†i nhi·ªÅu service |
|------------------|------------------------|-------------------|
| D·ªÖ qu·∫£n l√Ω        | ‚úÖ                      | ‚ùå |
| Backup ƒë∆°n gi·∫£n   | ‚úÖ Volume/pg_dump       | ‚ùå Kh√≥ h∆°n |
| Scale linh ho·∫°t   | ‚úÖ `--scale`            | ‚ùå Th·ªß c√¥ng |
| T√°ch bi·ªát service | ‚úÖ                      | ‚ùå |
| Dev ‚Üí Prod d·ªÖ     | ‚úÖ Build/Push/Tag       | ‚ùå |

---

## ‚úÖ Tag v√† Push Image

```bash
docker tag airflow-nptan:1.0.0 your_dockerhub_user/airflow-nptan:1.0.0
docker push your_dockerhub_user/airflow-nptan:1.0.0
```
-----------------------------------------------------------------------------


# üõ† README: Scripts, nginx.conf & .env Usage

## üìÅ 1. scripts/

Th∆∞ m·ª•c `scripts/` th∆∞·ªùng ch·ª©a c√°c file shell ho·∫∑c Python h·ªó tr·ª£ h·ªá th·ªëng Airflow nh∆∞:

| Script              | M·ª•c ƒë√≠ch |
|---------------------|----------|
| `init.sh`           | T·∫°o user, migrate db, kh·ªüi t·∫°o l·∫ßn ƒë·∫ßu |
| `backup.sh`         | Sao l∆∞u d·ªØ li·ªáu PostgreSQL ho·∫∑c DAGs |
| `restore.sh`        | Kh√¥i ph·ª•c d·ªØ li·ªáu t·ª´ b·∫£n sao l∆∞u |
| `healthcheck.sh`    | D√πng ƒë·ªÉ ki·ªÉm tra t√¨nh tr·∫°ng container |
| `generateKey.py`    | Sinh key m√£ ho√°, d√πng trong DAG |

> üìå T·∫•t c·∫£ file `.sh` c·∫ßn ƒë∆∞·ª£c g√°n quy·ªÅn ch·∫°y:
```bash
chmod +x scripts/*.sh
```

---

## üåê 2. nginx.conf

C·∫•u h√¨nh NGINX l√†m **reverse proxy** cho Airflow Webserver:

### ‚úÖ V√≠ d·ª• c·∫•u h√¨nh:

```nginx
server {
    listen 80;

    location / {
        proxy_pass http://localhost:8080;
        proxy_set_header Host $host;
        proxy_set_header X-Real-IP $remote_addr;
    }
}
```

### üì¶ Mount file v√†o container:

```yaml
services:
  access-hot-proxy:
    image: nginx
    volumes:
      - ./nginx.conf:/etc/nginx/nginx.conf:ro
    ports:
      - "80:80"
```

> üîê B·∫°n c√≥ th·ªÉ m·ªü r·ªông v·ªõi SSL (Let's Encrypt), ho·∫∑c ƒë·ªãnh tuy·∫øn nhi·ªÅu domain.

---

## üîê 3. File `.env`

File `.env` d√πng ƒë·ªÉ **qu·∫£n l√Ω bi·∫øn m√¥i tr∆∞·ªùng** ri√™ng bi·ªát theo t·ª´ng m√°y ho·∫∑c m√¥i tr∆∞·ªùng:

### V√≠ d·ª• `.env.mac`:

```env
AIRFLOW_IMAGE_NAME=apache/airflow:2.10.5-python3.12
AIRFLOW_UID=501
AIRFLOW_GID=20
_AIRFLOW_WWW_USER_USERNAME=tanp
_AIRFLOW_WWW_USER_PASSWORD=Vccb1234
```

### üîÑ S·ª≠ d·ª•ng `.env` trong `docker-compose.yml`:

```yaml
env_file: .env
```

Ho·∫∑c d√πng trong CLI:

```bash
cp .env.mac .env  # macOS
# ho·∫∑c
Copy-Item .env.windows -Destination .env  # Windows PowerShell
```

---

## ‚úÖ T·ªïng k·∫øt

| Th√†nh ph·∫ßn | Vai tr√≤ | Khuy·∫øn ngh·ªã |
|------------|---------|-------------|
| scripts/   | T·ª± ƒë·ªông h√≥a qu·∫£n l√Ω Airflow | T√°ch bi·ªát logic r√µ r√†ng |
| nginx.conf | Reverse proxy + SSL         | Mount v√†o container |
| .env       | Bi·∫øn m√¥i tr∆∞·ªùng c·∫•u h√¨nh    | D√πng theo t·ª´ng m√¥i tr∆∞·ªùng |

-----------------------------------------------------------------------------
# üöÄ README: DAGs, Dockerfile, v√† CI/CD cho Airflow

---

## üìÇ 1. DAGs ‚Äì T·∫≠p tin ƒëi·ªÅu khi·ªÉn workflow

### üìÅ Th∆∞ m·ª•c: `dags/`

Ch·ª©a c√°c file `.py` ƒë·ªãnh nghƒ©a workflow v√† c√°c task c·ªßa b·∫°n trong Airflow.

### ‚úÖ C·∫•u tr√∫c DAG c∆° b·∫£n:

```python
from airflow import DAG
from airflow.operators.python import PythonOperator
from datetime import datetime

with DAG("sample_dag", start_date=datetime(2023, 1, 1), schedule_interval="@daily") as dag:
    def task_fn():
        print("Hello from Airflow!")

    t1 = PythonOperator(
        task_id="say_hello",
        python_callable=task_fn
    )
```

### üí° L∆∞u √Ω:
- T√™n file `.py` kh√¥ng ƒë∆∞·ª£c ch·ª©a k√Ω t·ª± ƒë·∫∑c bi·ªát
- Lu√¥n ƒë·∫∑t DAG trong `with DAG(...)` block
- G√°n `dag_id` duy nh·∫•t cho m·ªói DAG

---

## üê≥ 2. Dockerfile ‚Äì ƒê·ªãnh nghƒ©a image c·ªßa b·∫°n

### ‚úÖ Dockerfile chu·∫©n cho Airflow m·ªü r·ªông:

```Dockerfile
ARG AIRFLOW_IMAGE_NAME
FROM ${AIRFLOW_IMAGE_NAME}

USER root

RUN apt-get update &&     apt-get install -y openjdk-11-jdk &&     apt-get clean

ENV JAVA_HOME=/usr/lib/jvm/java-11-openjdk-amd64
ENV PATH="$JAVA_HOME/bin:$PATH"

USER airflow
COPY airflow.requirements.txt .
RUN pip install --no-cache-dir -r airflow.requirements.txt
```

> üí° Image base: `apache/airflow:2.10.5-python3.12`

---

## üîÑ 3. CI/CD ‚Äì T·ª± ƒë·ªông ho√° build & deploy

### üéØ M·ª•c ti√™u CI/CD:
- T·ª± ƒë·ªông build Docker image
- Push l√™n Docker Hub
- Deploy Airflow stack

---

### ‚úÖ V√≠ d·ª• GitHub Actions workflow (`.github/workflows/airflow.yml`):

```yaml
name: Build & Push Airflow Image

on:
  push:
    branches: [ main ]

jobs:
  build:
    runs-on: ubuntu-latest

    steps:
    - name: Checkout code
      uses: actions/checkout@v3

    - name: Set up Docker Buildx
      uses: docker/setup-buildx-action@v2

    - name: Log in to Docker Hub
      uses: docker/login-action@v2
      with:
        username: ${{ secrets.DOCKER_USER }}
        password: ${{ secrets.DOCKER_PASS }}

    - name: Build & Push Image
      uses: docker/build-push-action@v4
      with:
        context: .
        push: true
        tags: your_dockerhub_user/airflow-nptan:latest
```

### ‚úÖ Secrets b·∫°n c·∫ßn set trong GitHub:
- `DOCKER_USER`
- `DOCKER_PASS`

---

## üß† G·ª£i √Ω CI/CD n√¢ng cao:
| M·ª•c ti√™u                  | C√¥ng c·ª• |
|---------------------------|---------|
| Ch·∫°y test DAG             | `pytest`, `airflow dags test` |
| Lint Python               | `flake8`, `black`              |
| Tri·ªÉn khai l√™n production | SSH deploy, AWS ECS, K8s, GKE  |

---

## ‚úÖ T·ªïng k·∫øt

| Th√†nh ph·∫ßn | M·ª•c ti√™u | Ghi ch√∫ |
|------------|----------|--------|
| DAGs       | L·∫≠p l·ªãch v√† ch·∫°y task | N√™n ki·ªÉm tra b·∫±ng `airflow dags test` |
| Dockerfile | X√¢y d·ª±ng m√¥i tr∆∞·ªùng    | T√°ch bi·ªát r√µ r√†ng c√°c lib c·∫ßn thi·∫øt |
| CI/CD      | T·ª± ƒë·ªông ho√° build/deploy | S·ª≠ d·ª•ng GitHub Actions l√† d·ªÖ nh·∫•t |

-----------------------------------------------------------------------------
# üîå README: Airflow Plugins & Command-line Management

## üîå 1. Airflow Plugins

Airflow h·ªó tr·ª£ plugin ƒë·ªÉ m·ªü r·ªông t√≠nh nƒÉng ‚Äî nh∆∞ th√™m operators, sensors, hooks, macros, v√† Flask views.

### üìÅ C·∫•u tr√∫c th∆∞ m·ª•c plugins/:
``` 
plugins/
‚îú‚îÄ‚îÄ __init__.py
‚îú‚îÄ‚îÄ custom_operator.py
‚îú‚îÄ‚îÄ custom_hook.py
‚îú‚îÄ‚îÄ my_plugin.py
```
	üîÅ Airflow s·∫Ω t·ª± ƒë·ªông load t·∫•t c·∫£ c√°c file .py trong plugins/ m·ªói l·∫ßn kh·ªüi ƒë·ªông.

### ‚úÖ V√≠ d·ª• 1: Plugin operator

```python
# plugins/custom_operator.py
from airflow.models import BaseOperator

class HelloOperator(BaseOperator):
    def execute(self, context):
        print("Xin ch√†o t·ª´ plugin!")
```

### ‚úÖ V√≠ d·ª• 2: ƒêƒÉng k√Ω plugin

```python
# plugins/my_plugin.py
from airflow.plugins_manager import AirflowPlugin
from .custom_operator import HelloOperator

class MyAirflowPlugin(AirflowPlugin):
    name = "my_custom_plugin"
    operators = [HelloOperator]
```

## ‚öôÔ∏è 2. L·ªánh qu·∫£n l√Ω Airflow (CLI)

### ‚úÖ C∆° b·∫£n
```bash
airflow db init               # Kh·ªüi t·∫°o database l·∫ßn ƒë·∫ßu
airflow db upgrade            # C·∫≠p nh·∫≠t schema database
airflow users create          # T·∫°o user ƒëƒÉng nh·∫≠p
airflow webserver             # Ch·∫°y web UI
airflow scheduler             # Ch·∫°y scheduler
```

### ‚úÖ DAG management

```bash
airflow dags list                     # Li·ªát k√™ c√°c DAG
airflow dags trigger <dag_id>        # K√≠ch ho·∫°t DAG th·ªß c√¥ng
airflow dags pause <dag_id>          # D·ª´ng ch·∫°y DAG theo schedule
airflow dags unpause <dag_id>        # Cho ph√©p DAG ch·∫°y theo schedule
```

### ‚úÖ Task management

```bash
airflow tasks list <dag_id>                           # Li·ªát k√™ task trong DAG
airflow tasks test <dag_id> <task_id> <exec_date>     # Test task c·ª•c b·ªô
```

### ‚úÖ Monitoring & Debug

```bash
airflow info                  # Xem th√¥ng tin c·∫•u h√¨nh
airflow config get-value core dags_folder
airflow plugins list          # Li·ªát k√™ plugin ƒë√£ ƒë∆∞·ª£c load
```

## üß† G·ª£i √Ω khi d√πng plugins:

| **L∆∞u √Ω**     | **M·∫πo**                               |
|---------------|---------------------------------------|
| Load ch·∫≠m?	| Ki·ªÉm tra log khi kh·ªüi ƒë·ªông webserver  |
|---------------|---------------------------------------|
| Debug plugin	| D√πng airflow plugins list             |
|---------------|---------------------------------------|
| Reusable code	| T√°ch r√µ file .py trong plugins/       |
|---------------|---------------------------------------|
| Reload plugin	| Ph·∫£i restart webserver/scheduler      |
---------------------------------------------------------

-----------------------------------------------------------------------------

# üöÄ Giao di·ªán Web Airflow ‚Äì T·ªïng Quan

Truy c·∫≠p web UI qua:
üëâ http://localhost:8080 (m·∫∑c ƒë·ªãnh)
ƒêƒÉng nh·∫≠p b·∫±ng t√†i kho·∫£n b·∫°n ƒë√£ c·∫•u h√¨nh:

```bash
Username: tanp
Password: Vccb1234
```

## üß≠ C√°c th√†nh ph·∫ßn ch√≠nh tr√™n Web UI

| **M·ª•c**                 |	**M√¥ t·∫£**
|-------------------------|-----------------------------------------------------------|
| DAGs	                  | Danh s√°ch c√°c DAG ƒë∆∞·ª£c ph√°t hi·ªán trong th∆∞ m·ª•c dags/
|-------------------------|-----------------------------------------------------------|
| Tree View	              | Bi·ªÉu ƒë·ªì DAG d·∫°ng c√¢y: c√°c task theo ng√†y ch·∫°y
|-------------------------|-----------------------------------------------------------|
| Graph View	          | DAG hi·ªÉn th·ªã theo d·∫°ng node ‚Äì gi√∫p d·ªÖ h√¨nh dung pipeline
|-------------------------|-----------------------------------------------------------|
| Code	                  | Xem source code Python c·ªßa DAG
|-------------------------|-----------------------------------------------------------|
| Trigger DAG	          | K√≠ch ho·∫°t DAG th·ªß c√¥ng
|-------------------------|-----------------------------------------------------------|
| Pause/Unpause	          | B·∫≠t/t·∫Øt ch·∫°y DAG theo schedule
|-------------------------|-----------------------------------------------------------|
| Admin ‚Üí Connections     |	Qu·∫£n l√Ω k·∫øt n·ªëi ƒë·∫øn DB, API, SFTP,‚Ä¶
|-------------------------|-----------------------------------------------------------|
| Admin ‚Üí Variables	      | Bi·∫øn m√¥i tr∆∞·ªùng to√†n c·ª•c cho DAG
|-------------------------|-----------------------------------------------------------|
| Admin ‚Üí Pools	          | Gi·ªõi h·∫°n s·ªë task ch·∫°y song song
|-------------------------|-----------------------------------------------------------|
| Browse ‚Üí Task Instances |	Theo d√µi t·ª´ng l·∫ßn ch·∫°y c·ªßa task
|-------------------------|-----------------------------------------------------------|
| Browse ‚Üí Logs	          | Xem log task ch·∫°y th·∫•t b·∫°i/th√†nh c√¥ng
|-------------------------|-----------------------------------------------------------|
| Browse ‚Üí DAG Runs	      | Danh s√°ch c√°c l·∫ßn ch·∫°y c·ªßa m·ªói DAG

### üîß 1. C·∫•u h√¨nh Connections
    1.	Truy c·∫≠p: Admin ‚Üí Connections
	2.	Nh·∫•n ‚ûï ƒë·ªÉ t·∫°o k·∫øt n·ªëi m·ªõi
	3.	V√≠ d·ª• t·∫°o k·∫øt n·ªëi PostgreSQL:

| **Field**    | **Value**
|--------------|----------------------------------------|
| Conn Id	   | my_postgres
|--------------|----------------------------------------|
| Conn Type	   | Postgres
|--------------|----------------------------------------|
| Host	       | postgres (t√™n service trong compose)
|--------------|----------------------------------------|
| Schema	   | airflow
|--------------|----------------------------------------|
| Login	       | airflow
|--------------|----------------------------------------|
| Password	   | airflow
|--------------|----------------------------------------|
| Port	       | 5432
|--------------|----------------------------------------|

**üß™ B·∫°n c√≥ th·ªÉ test b·∫±ng Python operator d√πng:**
```python
PostgresHook(postgres_conn_id="my_postgres")
```

### üß∞ 2. C·∫•u h√¨nh Variables (Admin ‚Üí Variables)

D√πng ƒë·ªÉ truy·ªÅn bi·∫øn to√†n c·ª•c v√†o DAG:
	‚Ä¢	V√≠ d·ª• key: email_list
	‚Ä¢	Value: ["dev@example.com", "admin@example.com"]

Sau ƒë√≥ d√πng trong DAG:

```python
from airflow.models import Variable

emails = Variable.get("email_list", deserialize_json=True)
```

### üõë 3. D·ª´ng/Ch·∫°y DAG

	*	üîò Pause DAG: D·ª´ng ch·∫°y theo l·ªãch (schedule_interval)
	*	‚ñ∂Ô∏è Unpause DAG: B·∫≠t l·∫°i t·ª± ƒë·ªông ch·∫°y
	*	üîÑ Trigger DAG: Ch·∫°y th·ªß c√¥ng 1 l·∫ßn

### üß™ 4. Ki·ªÉm tra Log Task

	*	V√†o Browse ‚Üí DAG Runs ‚Üí Task Instance
	*	Ch·ªçn 1 task ‚Üí b·∫•m ‚ÄúLog‚Äù ƒë·ªÉ xem chi ti·∫øt
	*	C√≥ th·ªÉ th·∫•y traceback khi task l·ªói

### üîê 5. Th√™m ng∆∞·ªùi d√πng

T·ª´ terminal:
```bash
airflow users create \
  --username admin \
  --firstname Admin \
  --lastname User \
  --role Admin \
  --email admin@example.com \
  --password yourpassword
```

## üìä T√πy ch·ªânh Web UI th√™m:

	‚Ä¢	C√†i theme: pip install airflow-theme
	‚Ä¢	S·ª≠a favicon/logo: Override Flask template (n√¢ng cao)
	‚Ä¢	Th√™m menu m·ªõi: vi·∫øt plugin flask_blueprint (n√¢ng cao)

## ‚úÖ K·∫øt lu·∫≠n

| **Vi·ªác c·∫ßn l√†m**         |  	**Th·ª±c hi·ªán ·ªü ƒë√¢u**
|--------------------------|----------------------------|
| T·∫°o DAG, Trigger DAG     | Trang DAGs
|--------------------------|----------------------------|
| Xem log, tr·∫°ng th√°i task | Browse ‚Üí Task Instances
|--------------------------|----------------------------|
| Qu·∫£n l√Ω DB/API‚Ä¶	       | Admin ‚Üí Connections
|--------------------------|----------------------------|
| L∆∞u bi·∫øn to√†n c·ª•c	       | Admin ‚Üí Variables
|--------------------------|----------------------------|
| T·∫°o ng∆∞·ªùi d√πng	       | CLI ho·∫∑c Admin UI
|--------------------------|----------------------------|


-----------------------------------------------------------------------------


# ‚òÅÔ∏èüìà Apache Airflow ‚Äì T√≠ch h·ª£p v·ªõi Cloud, Datalake & Machine Learning

## 1Ô∏è‚É£ Kh·∫£ nƒÉng t√≠ch h·ª£p v·ªõi Databricks, Cloud, Data Lake

Apache Airflow h·ªó tr·ª£ k·∫øt n·ªëi v√† orchestration v·ªõi c√°c n·ªÅn t·∫£ng cloud v√† data lake th√¥ng qua c√°c **providers**:

| D·ªãch v·ª•         | M√¥ t·∫£ h·ªó tr·ª£                                 |
|------------------|---------------------------------------------|
| Databricks       | Hook, operator ƒë·ªÉ submit job l√™n DB         |
| AWS              | S3, EMR, Lambda, ECS, Glue...               |
| GCP              | BigQuery, Cloud Composer, GKE               |
| Azure            | Data Lake, Synapse, ML Service              |
| Snowflake        | Query tr·ª±c ti·∫øp, run warehouse              |
| HDFS / MinIO     | L∆∞u tr·ªØ DAG ho·∫∑c batch ƒë·∫ßu v√†o              |

## 2Ô∏è‚É£ T√≠ch h·ª£p & b·ªï tr·ª£ cho Machine Learning

Airflow l√† c√¥ng c·ª• orchestrator, r·∫•t t·ªët ƒë·ªÉ:
	‚Ä¢	X√¢y d·ª±ng MLOps pipeline
	‚Ä¢	T·ª± ƒë·ªông ho√° c√°c b∆∞·ªõc ML:
	‚Ä¢	Thu th·∫≠p d·ªØ li·ªáu
	‚Ä¢	Ti·ªÅn x·ª≠ l√Ω
	‚Ä¢	Train model
	‚Ä¢	Evaluate
	‚Ä¢	Deploy

	‚úÖ D√πng t·ªët v·ªõi MLflow, Metaflow, ho·∫∑c tr·ª±c ti·∫øp v·ªõi TensorFlow, scikit-learn‚Ä¶

## 3Ô∏è‚É£ T√≠ch h·ª£p TensorFlow

 c√≥ th·ªÉ:
	‚Ä¢	Vi·∫øt PythonOperator ƒë·ªÉ g·ªçi h√†m train model
	‚Ä¢	G·ªçi shell script ho·∫∑c submit job l√™n Spark/TensorFlow Cluster
	‚Ä¢	Ghi log v√†o MLflow / Neptune / WandB

```python
def train_model():
    import tensorflow as tf
    model = tf.keras.Sequential([...])
    model.compile(...)
    model.fit(...)

PythonOperator(
    task_id="train_ai_model",
    python_callable=train_model
)
```
## 4Ô∏è‚É£ ∆Øu nh∆∞·ª£c ƒëi·ªÉm c·ªßa Airflow:

| ∆Øu ƒëi·ªÉm                           | Nh∆∞·ª£c ƒëi·ªÉm                             |
|----------------------------------|----------------------------------------|
| ‚úÖ Qu·∫£n l√Ω DAG b·∫±ng Python        | ‚ùå Kh√¥ng t·ªëi ∆∞u cho real-time streaming |
| ‚úÖ Web UI ƒë·∫πp, d·ªÖ d√πng            | ‚ùå Kh·ªüi ƒë·ªông ch·∫≠m n·∫øu DAG l·ªõn           |
| ‚úÖ H·ªó tr·ª£ retry, SLA, alert      | ‚ùå Kh√¥ng t·ªët cho task c·ª±c ng·∫Øn          |
| ‚úÖ R·∫•t nhi·ªÅu provider cloud       | ‚ùå C·∫ßn c·∫•u h√¨nh nhi·ªÅu n·∫øu d√πng K8s      |
| ‚úÖ R·∫•t m·∫°nh v·ªÅ orchestrate logic | ‚ùå Kh√¥ng c√≥ model registry built-in     |

## 5Ô∏è‚É£ So s√°nh v·ªõi c√°c framework kh√°c

| Tool              | Open Source | ƒêi·ªÉm m·∫°nh                | Y·∫øu ƒëi·ªÉm / H·∫°n ch·∫ø                  |
|-------------------|-------------|--------------------------|--------------------------------------|
| **Airflow**       | ‚úÖ           | Linh ho·∫°t, ph·ªï bi·∫øn       | Kh√¥ng real-time                      |
| Prefect           | ‚úÖ           | D·ªÖ d√πng, DAG nh∆∞ Python   | Giao di·ªán mi·ªÖn ph√≠ c√≤n h·∫°n ch·∫ø       |
| Dagster           | ‚úÖ           | Typed DAG, Data-aware     | M·ªõi h∆°n, √≠t c·ªông ƒë·ªìng h∆°n            |
| Luigi             | ‚úÖ           | Nh·∫π, √≠t ph·ª• thu·ªôc         | Kh√¥ng c√≥ web UI, ƒë√£ c≈©               |
| Azure Data Factory| ‚ùå           | T√≠ch h·ª£p Azure t·ªët        | Kh√¥ng m·ªü r·ªông, ph·ª• thu·ªôc Microsoft   |
| GCP Composer      | ‚ùå           | Qu·∫£n l√Ω airflow tr√™n cloud | Chi ph√≠ cao, √≠t tu·ª≥ bi·∫øn             |
| AWS Step Functions| ‚ùå           | T√≠ch h·ª£p Lambda/S3 t·ªët    | Kh√¥ng vi·∫øt code thu·∫ßn Python         |

## ‚úÖ ƒê·ªÅ xu·∫•t

| T√¨nh hu·ªëng                    | C√¥ng c·ª• ph√π h·ª£p    |
|-------------------------------|--------------------|
| X√¢y d·ª±ng ETL/ELT + ML         | **Airflow**        |
| Workflow ƒë∆°n gi·∫£n, realtime   | Prefect, Dagster   |
| Azure-only                    | Azure Data Factory |
| ML tr√™n GCP                   | Airflow + BigQuery |
| MLOps + UI + Tracking         | Airflow + MLflow   |

-----------------------------------------------------------------------------
# ƒê√°nh gi√° v·ªÅ vi·ªác kh·∫Øc ph·ª•c nh∆∞·ª£c ƒëi·ªÉm data streaming c·ªßa airflow
# üîÑ Apache Airflow + Streaming: Kafka & Gi·∫£i ph√°p thay th·∫ø

## ‚ùì V·∫•n ƒë·ªÅ: Airflow kh√¥ng h·ªó tr·ª£ Streaming Real-time

*Apache Airflow ƒë∆∞·ª£c thi·∫øt k·∫ø ƒë·ªÉ x·ª≠ l√Ω c√°c batch jobs, theo l·ªãch tr√¨nh ƒë·ªãnh k·ª≥.*
***‚ö†Ô∏è Kh√¥ng ph√π h·ª£p cho x·ª≠ l√Ω event-driven ho·∫∑c streaming real-time nh∆∞:***
	‚Ä¢	Consume Kafka message m·ªói gi√¢y
	‚Ä¢	Trigger DAG khi c√≥ d·ªØ li·ªáu ƒë·∫©y t·ªõi
	‚Ä¢	X·ª≠ l√Ω continuous stream t·ª´ IoT, logs‚Ä¶

## 1Ô∏è‚É£ T√≠ch h·ª£p Apache Kafka v·ªõi Airflow

### ‚úÖ M·ª•c ti√™u:
	‚Ä¢	Airflow x·ª≠ l√Ω batch t·ª´ Kafka m·ªói X ph√∫t
	‚Ä¢	Ho·∫∑c Airflow trigger DAG khi detect file/message
### üì¶ C√°ch t√≠ch h·ª£p ph·ªï bi·∫øn:

C√°ch	             | M√¥ t·∫£
---------------------|-------------------------------------------------------------------|
Kafka Consumer DAG	 | DAG ch·∫°y m·ªói X ph√∫t, d√πng hook ƒë·ªÉ l·∫•y batch t·ª´ Kafka
---------------------|-------------------------------------------------------------------|
Sensor + Kafka	     | Vi·∫øt custom sensor, check Kafka message r·ªìi trigger task
---------------------|-------------------------------------------------------------------|
Kafka ‚Üí HTTP	     | Kafka push event ƒë·∫øn API ƒë·ªÉ trigger Airflow DAG (via REST API)
---------------------|-------------------------------------------------------------------|
Kafka ‚Üí DB ‚Üí Airflow | Kafka dump v√†o DB, Airflow d√πng ExternalTaskSensor
---------------------|-------------------------------------------------------------------|

### üîß V√≠ d·ª• s·ª≠ d·ª•ng Kafka Hook:

```python
from airflow.hooks.base_hook import BaseHook
from kafka import KafkaConsumer

def read_kafka():
    consumer = KafkaConsumer(
        'my-topic',
        bootstrap_servers='localhost:9092',
        auto_offset_reset='latest'
    )
    for msg in consumer:
        print(msg.value)
```

## 2Ô∏è‚É£ ∆Øu ‚Äì Nh∆∞·ª£c khi t√≠ch h·ª£p Kafka

| ∆Øu ƒëi·ªÉm                          | Nh∆∞·ª£c ƒëi·ªÉm                             |
|----------------------------------|----------------------------------------|
| ‚úÖ C√≥ th·ªÉ x·ª≠ l√Ω event theo batch | ‚ùå Kh√¥ng ph·∫£i real-time th·ª±c s·ª±        |
| ‚úÖ T·∫≠n d·ª•ng h·ªá th·ªëng Airflow s·∫µn | ‚ùå Kh√¥ng scale t·ªët theo t·ªëc ƒë·ªô Kafka   |
| ‚úÖ D·ªÖ debug v·ªõi web UI/log       | ‚ùå Complex n·∫øu d√πng sensor li√™n t·ª•c     |

## 3Ô∏è‚É£ Gi·∫£i ph√°p thay th·∫ø chuy√™n d·ª•ng streaming

| C√¥ng c·ª•          | ∆Øu ƒëi·ªÉm                                      | Nh∆∞·ª£c ƒëi·ªÉm                    |
|------------------|----------------------------------------------|-------------------------------|
| **Apache Flink** | Stream + batch, c·ª±c k·ª≥ m·∫°nh v·ªõi CEP         | H·ªçc h∆°i kh√≥, JVM-based        |
| Kafka Streams    | Nh·∫π, ch·∫°y trong microservices Java           | Ph·ª• thu·ªôc Kafka platform      |
| Spark Structured Streaming | Giao di·ªán d·ªÖ, scale t·ªët              | Delay cao n·∫øu x·ª≠ l√Ω nh·ªè       |
| NiFi             | GUI lu·ªìng d·ªØ li·ªáu tr·ª±c quan, support Kafka   | T√≠nh linh ho·∫°t th·∫•p h∆°n code  |
| Prefect + Kafka  | Event-based DAG h·ªó tr·ª£ native                | M·ªõi h∆°n, √≠t plugin cloud h∆°n  |

## 4Ô∏è‚É£ ƒê·ªÅ xu·∫•t

| M·ª•c ƒë√≠ch                     | N√™n d√πng g√¨            |
|------------------------------|------------------------|
| ETL batch m·ªói 15 ph√∫t        | Airflow + KafkaConsumer |
| Trigger DAG theo file/data   | Airflow + REST API      |
| Streaming real-time m·∫°nh     | Kafka + Flink/Spark     |
| DAG trigger theo event       | Prefect or Dagster      |
| T√≠ch h·ª£p Kafka + tracking    | NiFi + Airflow / Flink  |

## ‚úÖ T·ªïng k·∫øt

Airflow v·∫´n c√≥ th·ªÉ t∆∞∆°ng t√°c v·ªõi Kafka nh∆∞ng kh√¥ng n√™n d√πng cho streaming real-time.
üìå N·∫øu workload c·ªßa b·∫°n y√™u c·∫ßu < 5 ph√∫t/d·ªØ li·ªáu ‚Äì d√πng Prefect, Flink ho·∫∑c Spark Streaming l√† l·ª±a ch·ªçn t·ªët h∆°n.

-----------------------------------------------------------------------------
# üìÇ T√†i li·ªáu tham kh·∫£o

- [Apache Airflow Docs](https://airflow.apache.org/docs/)
- [Helm Chart Airflow](https://github.com/apache/airflow/tree/main/chart)

---

**‚úçÔ∏è T√°c gi·∫£:** nptan2005  
**üìÖ Generated:** 2025-04-19
